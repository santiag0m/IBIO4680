function coef = entropyCompare(estimate,truth)

if ~prod(size(estimate)==size(truth))
    error('The estimate and ground truth must have the same size')
end

[r,c] = size(estimate);
k = max(truth(:))- min(truth(:)) + 1; % Number of expected regions
coef = zeros(r,c); % Entropy difference coeficient matrix
dr = zeros(
for i=1:r
    er = discEntropy(estimate(i,:),k); % Estimate entropy per row
    tr = discEntropy(truth(i,:),k); % Truth entropy per row
    dr = abs(er-tr);
    for j=1:c
        ec = discEntropy(estimate(:,j),k); % Estimate entropy per column
        tc = discEntropy(truth(:,j),k); % Truth entropy per column
        dc = abs(ec-tc);
        coef(i,j) = max(dr,dc);
    end
end

coef = sum(coef(:))/(r*c*log(k)); % Normalized total entropy difference


function etp = discEntropy(x,k)

% Calcualte discrete entropy
h = histogram(x, k, 'Normalization', 'probability');
h = h.Values;
h(h==0) = 1;
etp = -sum(log(h).*h);

